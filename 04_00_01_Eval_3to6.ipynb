{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, optimizers, losses\n",
    "from utils import *\n",
    "from loss import *\n",
    "from network import *\n",
    "from metrics import *\n",
    "from ipywidgets import interact\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(y_pred, y_true, mode=12):\n",
    "    # img : [Slices, Height, Width, 12]\n",
    "    b, h, w, _ = y_pred.shape\n",
    "    \n",
    "    if mode == 12:\n",
    "        tmp_pred = y_pred[...,3:-3]\n",
    "        tmp_pred = np.transpose(tmp_pred, [0, 3, 1, 2])\n",
    "        tmp_pred = np.reshape(tmp_pred, [b*6, h, w])\n",
    "\n",
    "        tmp_true = y_true[...,3:-3]\n",
    "        tmp_true = np.transpose(tmp_true, [0, 3, 1, 2])\n",
    "        tmp_true = np.reshape(tmp_true, [b*6, h, w])\n",
    "    \n",
    "    elif mode ==6:\n",
    "        tmp_pred = np.transpose(y_pred, [0, 3, 1, 2])\n",
    "        tmp_pred = np.reshape(tmp_pred, [b*6, h, w])\n",
    "        \n",
    "        tmp_true = np.transpose(y_true, [0, 3, 1, 2])\n",
    "        tmp_true = np.reshape(tmp_true, [b*6, h, w])\n",
    "        \n",
    "        \n",
    "    max_idx = len(tmp_pred)-1\n",
    "    err = tmp_true-tmp_pred\n",
    "    err_min = (tmp_true-tmp_pred).min()\n",
    "    err_max = (tmp_true-tmp_pred).max()\n",
    "    \n",
    "    def plot(idx=0):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(131)\n",
    "        plt.title(\"y_pred\")\n",
    "        plt.imshow(tmp_pred[idx], cmap='gray', vmin=0, vmax=tmp_true.max())\n",
    "        plt.xlabel(\"%.2f\"%(tmp_pred[idx].max()))\n",
    "        plt.subplot(132)\n",
    "        plt.title(\"y_true\")\n",
    "        plt.imshow(tmp_true[idx], cmap='gray', vmax=tmp_true.max())\n",
    "        plt.xlabel(\"%.2f\"%(tmp_true[idx].max()))\n",
    "        plt.subplot(133)\n",
    "        plt.title(\"Error (true - pred)\")\n",
    "        plt.imshow(err[idx], cmap='gray', vmin = err_min, vmax=err_max)\n",
    "        #plt.xlabel(\"%.2f ~ %.2f\"%(err[idx].min(), err[idx].max()))\n",
    "    interact(plot, idx=(0, max_idx, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X's shape :  (303, 320, 256, 3)\n",
      "Train Y's shape :  (303, 320, 256, 6)\n",
      "Validation X's shape :  (25, 320, 256, 3)\n",
      "Validation Y's shape :  (25, 320, 256, 6)\n",
      "Test X's shape :  (328, 320, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "train_low, train_high, val_low, val_high, test_low = data_loader_v2('./interpolation/')\n",
    "print(\"Train X's shape : \", train_low.shape)\n",
    "print(\"Train Y's shape : \", train_high.shape)\n",
    "print(\"Validation X's shape : \", val_low.shape)\n",
    "print(\"Validation Y's shape : \", val_high.shape)\n",
    "print(\"Test X's shape : \", test_low.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './checkpoint/3to6/unet_l2_mi/'\n",
    "\n",
    "model_path = root_path+'model.json'\n",
    "train_csv_path = root_path+'train_loss.csv'\n",
    "val_csv_path = root_path+'val_loss.csv'\n",
    "\n",
    "weights_list = sorted(os.listdir(root_path))\n",
    "weights_list = [i for i in weights_list if '.h5' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0100_82120.15_34930.64.h5',\n",
       " '0200_39371.41_36263.26.h5',\n",
       " '0300_24488.82_36686.42.h5',\n",
       " '0400_18782.08_34189.55.h5',\n",
       " '0500_13827.60_35558.38.h5',\n",
       " '0600_12550.16_34438.00.h5',\n",
       " '0700_10482.90_34399.44.h5',\n",
       " '0800_10921.56_33133.08.h5',\n",
       " '0900_10387.04_34459.57.h5',\n",
       " '1000_8680.17_34307.16.h5',\n",
       " '1100_9925.18_34100.65.h5',\n",
       " '1200_7942.00_32596.69.h5',\n",
       " '1300_7960.06_35849.45.h5',\n",
       " '1400_6229.91_33849.95.h5',\n",
       " '1500_5913.94_33407.04.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with open(model_path, 'r') as f:\n",
    "    model_json = f.read()\n",
    "\n",
    "A = models.model_from_json(model_json)\n",
    "\n",
    "A.load_weights(root_path+weights_list[-1])\n",
    "\n",
    "# A = models.load_model(root_path+'model.h5', compile=False)\n",
    "# A.load_weights(root_path+weights_list[-2])\n",
    "\n",
    "# A = models.load_model(root_path+weights_list[-1], compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 320, 256, 6)\n",
      "(25, 320, 256, 6)\n"
     ]
    }
   ],
   "source": [
    "train_, _ = A.predict(train_low)\n",
    "val_, _ = A.predict(val_low)\n",
    "# train_ = A.predict(train_low)\n",
    "# val_ = A.predict(val_low)\n",
    "print(train_.shape)\n",
    "print(val_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  (303, 6) 0.9235502658651996 0.28143099684953227\n",
      "MSE :  (303, 6) 3.001669063228735 1.587299664523054\n",
      "RMSE :  (303, 6) 1.676322679934891 0.43773432120938344\n",
      "PSNR :  (303, 6) 42.75335522909292 2.4381400321461992\n"
     ]
    }
   ],
   "source": [
    "vmax = train_high.max(axis=(1, 2), keepdims=True)\n",
    "train_mae = MAE(train_high/vmax*255, train_/vmax*255)\n",
    "train_mse = MSE(train_high/vmax*255, train_/vmax*255)\n",
    "train_rmse = RMSE(train_high/vmax*255, train_/vmax*255)\n",
    "train_psnr = PSNR(train_high, train_)\n",
    "train_ssim = SSIM(train_high, train_)\n",
    "#train_mi = MI(train_high, train_)\n",
    "#train_mi = np.nan_to_num(train_mi)\n",
    "#train_nmi = NMI(train_high, train_)\n",
    "#train_nmi = np.nan_to_num(train_nmi)\n",
    "\n",
    "print('MAE : ', train_mae.shape, train_mae.mean(), train_mae.std())\n",
    "print('MSE : ', train_mse.shape, train_mse.mean(), train_mse.std())\n",
    "print('RMSE : ', train_rmse.shape, train_rmse.mean(), train_rmse.std())\n",
    "print('PSNR : ', train_psnr.shape, train_psnr.mean(), train_psnr.std())\n",
    "#print(train_ssim.shape, train_ssim.mean(), train_ssim.std())\n",
    "#print(train_mi.shape, train_mi.mean(), train_mi.std())\n",
    "#print(train_nmi.shape, train_nmi.mean(), train_nmi.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  (25, 6) 3.9457088639144065 1.467015975019767\n",
      "MSE :  (25, 6) 80.73966805578829 53.64436220965164\n",
      "RMSE :  (25, 6) 8.543982125851008 2.7820922861987825\n",
      "PSNR :  (25, 6) 33.81860208812682 1.8634457848063781\n"
     ]
    }
   ],
   "source": [
    "vmax = val_high.max(axis=(1, 2), keepdims=True)\n",
    "val_mae = MAE(val_high/vmax*255, val_/vmax*255)\n",
    "val_mse = MSE(val_high/vmax*255, val_/vmax*255)\n",
    "val_rmse = RMSE(val_high/vmax*255, val_/vmax*255)\n",
    "val_psnr = PSNR(val_high, val_)\n",
    "val_ssim = SSIM(val_high, val_)\n",
    "# val_mi = MI(val_high, val_)\n",
    "# val_mi = np.nan_to_num(val_mi)\n",
    "# val_nmi = NMI(val_high, val_)\n",
    "# val_nmi = np.nan_to_num(val_nmi)\n",
    "\n",
    "print('MAE : ', val_mae.shape, val_mae.mean(), val_mae.std())\n",
    "print('MSE : ', val_mse.shape, val_mse.mean(), val_mse.std())\n",
    "print('RMSE : ', val_rmse.shape, val_rmse.mean(), val_rmse.std())\n",
    "print('PSNR : ', val_psnr.shape, val_psnr.mean(), val_psnr.std())\n",
    "# print(val_ssim.shape, val_ssim.mean(), val_ssim.std())\n",
    "# print(val_mi.shape, val_mi.mean(), val_mi.std())\n",
    "# print(val_nmi.shape, val_nmi.mean(), val_nmi.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "MSE = \\frac{1}{n} \\sum^n{(y-\\hat{y})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum^n{(y-\\hat{y})^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "RMSPE = \\sqrt{\\frac{1}{n} \\sum^n({\\frac{y-\\hat{y}}{y}})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "PSNR = 10\\log_{10}(\\frac{MAX}{\\sqrt{MSE}}) = 20\\log_{10}{MAX} - 10\\log_{10}\\sqrt{MSE}\n",
    "$$\n",
    "\n",
    "$$\n",
    "SSIM = I(x,y)C(x,y)S(x,y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(root_path+'train_result', train_)\n",
    "np.save(root_path+'val_result', val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score as mi\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_np(y_true, y_pred):\n",
    "    hist2d, _, _ = np.histogram2d(y_true.ravel(), y_pred.ravel(), bins=255, range=[[0,255],[0,255]])    \n",
    "    pxy = hist2d / float(np.sum(hist2d))\n",
    "    px = np.sum(pxy, axis=1) # marginal for x over y\n",
    "    py = np.sum(pxy, axis=0) # marginal for y over x\n",
    "    px_py = px[:, None] * py[None, :] # Broadcast to multiply marginals    \n",
    "    nzs = pxy > 0 # Only non-zero pxy values contribute to the sum\n",
    "    return np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_new(y_true, y_pred):\n",
    "    hist2d, _, _ = np.histogram2d(y_true.ravel(), y_pred.ravel(), bins=255, range=[[0,255],[0,255]])    \n",
    "    pxy = hist2d / float(np.sum(hist2d))\n",
    "    px = np.sum(pxy, axis=1) # marginal for x over y\n",
    "    py = np.sum(pxy, axis=0) # marginal for y over x\n",
    "    hx = -np.sum(px*np.log(px))\n",
    "    hy = -np.sum(py*np.log(py))\n",
    "    hxy = -np.sum(pxy*np.log(pxy))\n",
    "    px_py = px[:, None] * py[None, :]\n",
    "    print(px.shape, py.shape, px_py.shape)\n",
    "    return 2*(hx+hy-hxy)/(hx+hy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_information_new(tmp_true, tmp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0\n",
    "sli = 0\n",
    "tmp_true = train_high[b, ..., sli]/train_high[b, ..., sli].max()*255\n",
    "tmp_pred = train_[b, ..., sli]/train_high[b, ..., sli].max()*255\n",
    "print(mi(tmp_true.ravel(), tmp_true.ravel()), mutual_information_np(tmp_true, tmp_true))\n",
    "print(nmi(tmp_true.ravel(), tmp_true.ravel()))\n",
    "print(mutual_information_new(tmp_true, tmp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test10 = val_high/val_high.max(axis=(1, 2), keepdims=True)\n",
    "test11 = val_/val_.max(axis=(1, 2), keepdims=True)\n",
    "test00 = train_high/train_high.max(axis=(1, 2), keepdims=True)\n",
    "test01 = train_/train_.max(axis=(1, 2), keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(train_, train_high, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(val_, val_high, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = pd.read_csv(train_csv_path)\n",
    "val_loss = pd.read_csv(val_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss.Generator_Style[:100])\n",
    "plt.plot(val_loss.Generator_Style[:100])\n",
    "plt.ylim((0, 10000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
