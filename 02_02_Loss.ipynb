{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 8, [6, 16, 16, 6])*1.0#tf.random.uniform([6, 320, 256, 12], maxval=vmax+1, dtype='int32')\n",
    "b = np.random.randint(0, 10, [6, 16, 16, 6])*1.0#tf.random.uniform([6, 320, 256, 12], maxval=vmax+1, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Custom_SSIM(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true : [batch, height, width, channel]\n",
    "    y_pred : [batch, height, width, channel]\n",
    "    \"\"\"\n",
    "    # b, h, w, c = tf.shape(y_true)\n",
    "    #print(tf.shape(y_true))\n",
    "\n",
    "    # [b, h, w, c] -> [b*c, h, w]\n",
    "    tmp_true = tf.reshape(tf.transpose(y_true, [0, 3, 1, 2]),\n",
    "                          [tf.shape(y_true)[0]*tf.shape(y_true)[3], tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    tmp_pred = tf.reshape(tf.transpose(y_pred, [0, 3, 1, 2]),\n",
    "                          [tf.shape(y_true)[0]*tf.shape(y_true)[3], tf.shape(y_true)[1], tf.shape(y_true)[2], 1])\n",
    "    max_val = tf.reduce_max(tmp_true, axis=(1, 2, 3), keepdims=True)-tf.reduce_min(tmp_true, axis=(1, 2, 3), keepdims=True)\n",
    "    \n",
    "    ssim = tf.image.ssim(tmp_true, tmp_pred, max_val=max_val)\n",
    "    \n",
    "    # ssim : [b*c, 1] -> [b, c]\n",
    "    ssim = tf.reshape(ssim, [tf.shape(y_true)[0], tf.shape(y_true)[3]])\n",
    "    \n",
    "    return (1.-ssim)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1 = tf.placeholder(shape=[None, None, None, None], dtype=tf.float64)\n",
    "ph2 = tf.placeholder(shape=[None, None, None, None], dtype=tf.float64)\n",
    "\n",
    "ssim = Custom_SSIM(ph1, ph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_test = sess.run(ssim, feed_dict={ph1:b, ph2:a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53628373, 0.5066118 , 0.483469  , 0.49045593, 0.45590618,\n",
       "        0.5755512 ],\n",
       "       [0.47619876, 0.6129287 , 0.52747065, 0.53778297, 0.44359028,\n",
       "        0.4475478 ],\n",
       "       [0.49658242, 0.4689433 , 0.5410947 , 0.4720045 , 0.46674955,\n",
       "        0.49124426],\n",
       "       [0.35568428, 0.5780693 , 0.46426848, 0.5180951 , 0.45292622,\n",
       "        0.53033787],\n",
       "       [0.49299815, 0.57605255, 0.47505072, 0.48900303, 0.53030723,\n",
       "        0.6142926 ],\n",
       "       [0.5248959 , 0.5601461 , 0.5389449 , 0.47243908, 0.4850606 ,\n",
       "        0.5661313 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_a = np.reshape(np.transpose(a, [0, 3, 1, 2]), [36, 16, 16, 1])\n",
    "f_b = np.reshape(np.transpose(b, [0, 3, 1, 2]), [36, 16, 16, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph3 = tf.placeholder(shape=[None, None, None], dtype=tf.float64)\n",
    "ph4 = tf.placeholder(shape=[None, None, None], dtype=tf.float64)\n",
    "\n",
    "tf_ssim = tf.image.ssim(ph3, ph4, max_val=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5661313459277153"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = -1\n",
    "(1-sess.run(tf_ssim, feed_dict={ph3:f_a[idx]/f_b[idx].max(), ph4:f_b[idx]/f_b[idx].max()}))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_single(hist2d):\n",
    "    tmp = tf.cast(hist2d, dtype='float64')\n",
    "    pxy = tmp / tf.reduce_sum(tmp)\n",
    "    px = tf.reduce_sum(pxy, axis=1)\n",
    "    py = tf.reduce_sum(pxy, axis=0)\n",
    "    px_py = px[:, None] * py[None, :]\n",
    "    nzs = tf.greater(pxy, 0)\n",
    "    return tf.reduce_sum(tf.boolean_mask(pxy, nzs) * tf.log(tf.boolean_mask(pxy, nzs) / tf.boolean_mask(px_py, nzs)))\n",
    "\n",
    "def tf_joint_histogram(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true : [batch, height, width, channel]\n",
    "    y_pred : [batch, height, width, channel]\n",
    "    \"\"\"\n",
    "    #print(\"joint1\")\n",
    "    vmax = 255\n",
    "    #b, h, w, c = tf.shape(y_true)\n",
    "    \n",
    "    \n",
    "    # Intensity Scaling\n",
    "    max_int = tf.reduce_max(y_true, axis = [1,2], keepdims=True)\n",
    "    tmp_true = tf.round(y_true / max_int * vmax)\n",
    "    tmp_pred = tf.round(y_pred / max_int * vmax)\n",
    "    \n",
    "    #print(\"joint2\")\n",
    "    # [batch, height, width, channel]\n",
    "    # -> [batch, height * width, channel]\n",
    "    # -> [batch, channel, height * width]\n",
    "    flat_true = tf.transpose(tf.reshape(tmp_true,\n",
    "                                        [tf.shape(y_true)[0], tf.shape(y_true)[1]*tf.shape(y_true)[2], tf.shape(y_true)[-1]]), [0, 2, 1])\n",
    "    flat_true = tf.reshape(flat_true, [tf.shape(y_true)[0]*tf.shape(y_true)[-1], tf.shape(y_true)[1]*tf.shape(y_true)[2]])\n",
    "    flat_pred = tf.transpose(tf.reshape(tmp_pred, [tf.shape(y_true)[0], tf.shape(y_true)[1]*tf.shape(y_true)[2], tf.shape(y_true)[-1]]), [0, 2, 1])\n",
    "    flat_pred = tf.reshape(flat_pred, [tf.shape(y_true)[0]*tf.shape(y_true)[-1], tf.shape(y_true)[1]*tf.shape(y_true)[2]])\n",
    "    #print(\"joint3\")\n",
    "    output = (flat_pred * (vmax+1)) + (flat_true+1)\n",
    "    #print(\"joint4\")\n",
    "    # [b*c, 65536]\n",
    "    output = tf.map_fn(lambda x : tf.cast(tf.histogram_fixed_width(x, value_range=[1, (vmax+1)**2], nbins=(vmax+1)**2), 'float32'), output)\n",
    "    # [b, c, 256, 256] -> [b, 256, 256, c]\n",
    "    output = tf.transpose(tf.reshape(output, [tf.shape(y_true)[0], tf.shape(y_true)[-1], vmax+1, vmax+1]), [0, 2, 3, 1])\n",
    "    #print(\"joint5\")\n",
    "    return output, y_true, y_pred\n",
    "\n",
    "def mutual_information(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true : [batch, height, width, channel]\n",
    "    y_pred : [batch, height, width, channel]\n",
    "    \"\"\"\n",
    "    # [b, 256, 256, c]\n",
    "    joint_histogram, _, _ = tf_joint_histogram(y_true, y_pred)\n",
    "    #b, h, w, c = tf.shape(joint_histogram)\n",
    "    #print(\"mutual1\")\n",
    "    # [b*c, 256, 256]\n",
    "    reshape_joint_histogram = tf.reshape(tf.transpose(joint_histogram, [0, 3, 1, 2]), [tf.shape(joint_histogram)[0]*tf.shape(joint_histogram)[-1], tf.shape(joint_histogram)[1], tf.shape(joint_histogram)[2]])\n",
    "    #print(\"mutual2\")\n",
    "    output = tf.map_fn(lambda x : mutual_information_single(x), reshape_joint_histogram, dtype=tf.float64)\n",
    "    #print(\"mutual3\")\n",
    "    output = tf.reshape(output, [tf.shape(joint_histogram)[0], tf.shape(joint_histogram)[-1]])\n",
    "    return tf.cast(-tf.reduce_mean(output, axis=1), 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1 = tf.placeholder(shape=[None, None, None, None], dtype=tf.float32)\n",
    "ph2 = tf.placeholder(shape=[None, None, None, None], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2d = mutual_information(ph1, ph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sess.run(hist2d, feed_dict={ph1:a, ph2:b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7322901 , 0.7136585 , 0.7664927 , 0.7276379 , 0.7035092 ,\n",
       "       0.71937126], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
